{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoOfuMUgea2KveWew3PbyD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saim-Hassan786/Agentic-AI-With-OpenAI-Agents-SDK/blob/main/12-ModelSettings/ModelSettings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ModelSettings\n",
        "ModelSettings are regarded the configurations of parameters that help us control or instruct the model behaviour based on our requirements. It can be passed in both **Agent** and **Runner** Class as well, but the settings passed in Runner Class will override all the settings passed in Agent Class."
      ],
      "metadata": {
        "id": "g6RFY2xKN-MT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhrHYsAdzNny",
        "outputId": "05b7a34d-cf75-4f69-e3ac-d16f98dac059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installing the SDK\n",
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For running event loop\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "J9rYqXSSzYEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre requisites SetUp\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY= userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "from agents import set_default_openai_api,set_default_openai_client,set_tracing_disabled\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")\n",
        "set_default_openai_client(external_client)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "set_tracing_disabled(True)"
      ],
      "metadata": {
        "id": "JaFph2tAzaJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ModelSettings With Agent"
      ],
      "metadata": {
        "id": "t9gtPLRLgtT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent,Runner,ModelSettings\n",
        "\n",
        "agent_with_model_settings = Agent(\n",
        "    name=\"Agent with Model Settings\",\n",
        "    instructions =\"Reply user queries based on your Model Settings\",\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    model_settings = ModelSettings(\n",
        "       temperature = 1.7,            # can be btw 0.0 to 2.0\n",
        "       top_p= 0.9 ,                  # can be btw 0.0 to 1.0\n",
        "      # frequency_penalty= 1.0,      # can be btw -2.0 to 2.0  (Not Availale For Selected Model)\n",
        "      # presence_penalty= -1.0       # can be btw -2.0 to 2.0  (Not Availale For Selected Model)\n",
        "      tool_choice= \"auto\",           #  can be auto, required, or none\n",
        "      parallel_tool_calls= True,\n",
        "      max_tokens= 5000,\n",
        "      truncation= \"auto\" ,           # Cut the input when it exceeds the input context limit\n",
        "      reasoning =  None,             # controls the reasoning for reasoning models\n",
        "      # metadata = {\"name\": \"Saim\"}, # additional metadata stored with the response (Not Availale For Selected Model)\n",
        "      # store = True                 # whether to store the response for later retrieval (Not Availale For Selected Model)\n",
        "      include_usage = True ,         # whether to include the usage chunks in the response (Not Availale For Selected Model)\n",
        "      response_include = None ,      # additional output data to include in the response\n",
        "      extra_query = None ,           # additional query fields to provide with the request\n",
        "      extra_args = None ,            # arbitrary keyword arguments to pass to the model\n",
        "      extra_body= None ,             # additional body fields to provide with the request\n",
        "      extra_headers= None ,          # additional headers to provide with the request\n",
        "  )\n",
        ")"
      ],
      "metadata": {
        "id": "Vw4BaaDFRl6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_with_model_settings = await Runner.run(\n",
        "    agent_with_model_settings,\n",
        "    input = \"Hi there, tell me about AI in 100 words\"\n",
        ")\n",
        "print(result_with_model_settings.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lty-a__9S-zC",
        "outputId": "99a5be42-21e8-417b-c588-89638288d65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial Intelligence (AI) empowers machines to simulate human-like intelligence. It involves creating systems that can learn from data, reason, recognize patterns, understand language, and make decisions. Key AI subfields include Machine Learning, where algorithms improve performance with experience, and Deep Learning, which uses neural networks for complex tasks like image recognition and natural language processing. AI is transforming various sectors, from healthcare (diagnostics) and finance (fraud detection) to transportation (autonomous vehicles) and entertainment (recommendation engines). Its rapid advancement promises to revolutionize industries, enhance problem-solving capabilities, and create innovative solutions, reshaping our interaction with technology and the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runner With ModelSettings"
      ],
      "metadata": {
        "id": "dGnq9pqGg9U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent,Runner,ModelSettings,RunConfig\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Agent with Model Settings\",\n",
        "    instructions =\"Reply user queries based on your Model Settings\",\n",
        "    model = \"gemini-2.5-flash\",\n",
        ")\n",
        "\n",
        "runner_level_model_settings = ModelSettings(\n",
        "       temperature = 1.7,            # can be btw 0.0 to 2.0\n",
        "       top_p= 0.9 ,                  # can be btw 0.0 to 1.0\n",
        "      # frequency_penalty= 1.0,      # can be btw -2.0 to 2.0  (Not Availale For Selected Model)\n",
        "      # presence_penalty= -1.0       # can be btw -2.0 to 2.0  (Not Availale For Selected Model)\n",
        "      tool_choice= \"auto\",           #  can be auto, required, or none\n",
        "      parallel_tool_calls= True,\n",
        "      max_tokens= 5000,\n",
        "      truncation= \"auto\" ,           # Cut the input when it exceeds the input context limit\n",
        "      reasoning =  None,             # controls the reasoning for reasoning models\n",
        "      # metadata = {\"name\": \"Saim\"}, # additional metadata stored with the response (Not Availale For Selected Model)\n",
        "      # store = True                 # whether to store the response for later retrieval (Not Availale For Selected Model)\n",
        "      include_usage = True ,         # whether to include the usage chunks in the response (Not Availale For Selected Model)\n",
        "      response_include = None ,      # additional output data to include in the response\n",
        "      extra_query = None ,           # additional query fields to provide with the request\n",
        "      extra_args = None ,            # arbitrary keyword arguments to pass to the model\n",
        "      extra_body= None ,             # additional body fields to provide with the request\n",
        "      extra_headers= None ,          # additional headers to provide with the request\n",
        "  )"
      ],
      "metadata": {
        "id": "_EMG1w9sTKrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_with_model_settings_2 = await Runner.run(\n",
        "    agent,\n",
        "    input = \"Hi there, tell me about AI in 100 words\",\n",
        "    run_config = RunConfig(\n",
        "        model_settings = runner_level_model_settings\n",
        "    )\n",
        ")\n",
        "print(result_with_model_settings.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHEQNw4XhSUK",
        "outputId": "02b4ead8-0abc-446f-9c16-d86945c0ba6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial Intelligence (AI) empowers machines to simulate human-like intelligence. It involves creating systems that can learn from data, reason, recognize patterns, understand language, and make decisions. Key AI subfields include Machine Learning, where algorithms improve performance with experience, and Deep Learning, which uses neural networks for complex tasks like image recognition and natural language processing. AI is transforming various sectors, from healthcare (diagnostics) and finance (fraud detection) to transportation (autonomous vehicles) and entertainment (recommendation engines). Its rapid advancement promises to revolutionize industries, enhance problem-solving capabilities, and create innovative solutions, reshaping our interaction with technology and the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Always Keep it in mind that the Runner Level ModelSettings will override Agent Level ModelSettings"
      ],
      "metadata": {
        "id": "tvBwGjSChr7w"
      }
    }
  ]
}
