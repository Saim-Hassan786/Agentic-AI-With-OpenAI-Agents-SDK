# ðŸ“˜ Understanding `AgentOutputSchema`

This project demonstrates how to use **`AgentOutputSchema`** from the [`openai-agents`](https://pypi.org/project/openai-agents/) SDK to enforce structured output from LLMs. The goal is to ensure that the modelâ€™s responses strictly match a schema you define, using **Pydantic models** for validation.


## ðŸš€ Key Concepts

### ðŸ”¹ 1. Agent and Output Type

An `Agent` represents a conversational AI powered by an LLM (here, **Gemini-2.5-Flash**).

* Each `Agent` has:

  * **name** â†’ Identifier for the agent.
  * **instructions** â†’ System-level prompt guiding the agent.
  * **model** â†’ The LLM backend.
  * **output\_type** â†’ Defines the expected format of the agentâ€™s output.

The **`output_type`** is crucial:

* If itâ€™s a string â†’ the agent outputs plain text.
* If itâ€™s a **Pydantic model** â†’ the agent must respond in structured JSON matching the modelâ€™s schema.
* If itâ€™s wrapped in **`AgentOutputSchema`** â†’ stricter schema enforcement and validation apply.


### ðŸ”¹ 2. `AgentOutputSchemaBase`

`AgentOutputSchemaBase` is the abstract base for schema handling. It provides:

* `is_plain_text()` â†’ checks if schema expects free text.
* `json_schema()` â†’ generates the JSON schema for the LLM.
* `is_strict_json_schema()` â†’ enforces strict validation (no extra fields allowed).
* `validate_json()` â†’ validates LLM responses against the schema.
* `name()` â†’ returns schema name.


### ðŸ”¹ 3. Cases of `output_type`

#### ðŸŸ¢ Case 1: `output_type = str` or `None`

* Model returns plain text only.
* No schema applied.
* No validation performed.

#### ðŸŸ¡ Case 2: `output_type = Pydantic Model` or `AgentOutputSchema`

* A proper **JSON schema** is generated.
* LLM is instructed to respond in JSON.
* SDK validates and parses response into your model.
* Guarantees structured, predictable outputs.

#### ðŸ”´ Case 3: `output_type = primitive type` (e.g., `int`, `list`, `float`)

* Primitives arenâ€™t directly supported in JSON schema.
* SDK wraps them inside a dict like `{ "output": 123 }`.
* LLM responds in wrapped format â†’ unwrapped after validation.


## ðŸ§ª Code Walkthrough

### âœ… Example 1: Pydantic Output Type

```python
class OutputType(BaseModel):
    reasoning : str
    response : str
    is_response_correct : bool
```

* The agent returns a structured JSON with reasoning, response, and a correctness flag.
* Output is automatically validated and parsed into `OutputType`.


### âœ… Example 2: AgentOutputSchema

```python
class OutputType2(BaseModel):
    is_home_work_question : bool
    response : str
    is_response_correct : bool
```

* Here we wrap it with `AgentOutputSchema(output_type=OutputType2, strict_json_schema=True)`.
* This enforces **strict validation** â†’ no missing/extra fields allowed.
* Example response:

  ```json
  {
    "is_home_work_question": false,
    "response": "The capital of France is Paris and the capital of Germany is Berlin.",
    "is_response_correct": true
  }
  ```

### âœ… Schema Introspection

You can directly inspect the schema:

```python
print(output_schema.is_plain_text())
print(output_schema.is_strict_json_schema())
print(output_schema.json_schema())
print(output_schema.name())
print(output_schema.validate_json(json_str=json_str))
```

This helps in debugging and verifying what the LLM is being asked to produce.

## ðŸ“Š Summary

* **Plain text outputs** are unstructured (Case 1).
* **Pydantic models** enforce structure (Case 2).
* **AgentOutputSchema** ensures **strict schema compliance** and validation.
* **Primitive types** are wrapped to maintain consistency (Case 3).


## ðŸŽ¯ Why Use `AgentOutputSchema`?

* Ensures **reliable, structured responses** from LLMs.
* Prevents schema drift or unexpected formats.
* Enables downstream automation (agents, workflows) where strict types are required.
* Ideal for use cases like:

  * Homework/quiz detection.
  * JSON API responses.
  * Reasoning + final answer separation.
  * Any pipeline that depends on predictable output.

## âœ… Conclusion

`AgentOutputSchema` is a powerful way to **bridge the gap between flexible LLM outputs and strict application requirements**. By combining LLM reasoning with **typed validation**, you get reliable, structured, and machine-usable results.
enforcement â†’ validation â†’ final structured result, for the README?

