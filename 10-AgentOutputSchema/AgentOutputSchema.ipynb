{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOInWEb+oGa9GUde5eQnho/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saim-Hassan786/Agentic-AI-With-OpenAI-Agents-SDK/blob/main/10-AgentOutputSchema/AgentOutputSchema.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AgentOutputSchema\n",
        "AgentOutputschema is used to handle the output of the SDK produced via LLM to make it same to the type of the output defined in the **output_type** parameter of the Agent class."
      ],
      "metadata": {
        "id": "An1pwIBI3R_4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW2j-jEZSOaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5527b4d0-f336-4b37-93d0-eafdc03d5c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installing the SDK\n",
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For running event loop\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "J0GarRCRemG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre requisites SetUp\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY= userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "from agents import set_default_openai_api,set_default_openai_client,set_tracing_disabled\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")\n",
        "set_default_openai_client(external_client)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "set_tracing_disabled(True)"
      ],
      "metadata": {
        "id": "P6_-ns8JYQX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AgentOutputSchemaBase\n",
        "AgentOutputSchemaBase is the base class for the AgentOutputSchema and implements the following methods in it :\n",
        "\n",
        "1. **is_plain_text**\n",
        "2. **json_schema**\n",
        "3. **is_strict_json_schema**\n",
        "4. **validate_json**\n",
        "5. **name**"
      ],
      "metadata": {
        "id": "RB4k_X7W4Gyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple output_type code\n",
        "from agents import Agent,Runner\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class OutputType(BaseModel):\n",
        "    reasoning : str\n",
        "    response : str\n",
        "    is_response_correct : bool\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Simple Assistant ChatBot\",\n",
        "    instructions= \"You are a simple assistant that helps user with their queries\",\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    output_type = OutputType\n",
        ")\n",
        "result = await Runner.run(\n",
        "    starting_agent=agent,\n",
        "    input=\"What are artificial neural networks in 2 lines?\",\n",
        ")\n",
        "print(result.final_output)\n",
        "print(result.final_output.reasoning)\n",
        "print(result.final_output.response)\n",
        "print(result.final_output.is_response_correct)\n"
      ],
      "metadata": {
        "id": "EunmGdKuT2bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e3634a-1384-4ffd-81ef-862db2946b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reasoning='The response provides a two-line summary defining Artificial Neural Networks.' response='Artificial Neural Networks (ANNs) are computational models inspired by the human brain, designed to recognize patterns and learn from data.\\nThey consist of interconnected nodes (neurons) organized in layers that process information and adjust connection strengths (weights) to improve performance.' is_response_correct=True\n",
            "The response provides a two-line summary defining Artificial Neural Networks.\n",
            "Artificial Neural Networks (ANNs) are computational models inspired by the human brain, designed to recognize patterns and learn from data.\n",
            "They consist of interconnected nodes (neurons) organized in layers that process information and adjust connection strengths (weights) to improve performance.\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with AgentOutputSchema\n",
        "from agents import Agent,Runner,AgentOutputSchema\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class OutputType2(BaseModel):\n",
        "    is_home_work_question : bool\n",
        "    response : str\n",
        "    is_response_correct : bool\n",
        "\n",
        "agent2 = Agent(\n",
        "    name=\"Simple Assistant ChatBot\",\n",
        "    instructions= \"You are a simple assistant that helps user with their queries\",\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    output_type= AgentOutputSchema(output_type=OutputType2,strict_json_schema=True)\n",
        ")\n",
        "result2 = await Runner.run(\n",
        "    starting_agent=agent2,\n",
        "    input=\"What are the capitals of France and Germany?\",\n",
        ")\n",
        "print(result2.final_output)\n",
        "print(result2.final_output.is_home_work_question)\n",
        "print(result2.final_output.response)\n",
        "print(result2.final_output.is_response_correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I06QvP9x5TdL",
        "outputId": "4631b7b3-e58f-45c8-f153-b7753a0e0155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is_home_work_question=False response='The capital of France is Paris and the capital of Germany is Berlin.' is_response_correct=True\n",
            "False\n",
            "The capital of France is Paris and the capital of Germany is Berlin.\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters of AgentOutputSchema"
      ],
      "metadata": {
        "id": "PvJVtLOw9x62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_str = '{\"is_home_work_question\": true, \"response\": \"Yes, this is homework.\", \"is_response_correct\": false}'\n",
        "output_schema = AgentOutputSchema(output_type=OutputType2,strict_json_schema=True)\n",
        "print(\"Plain Text?\", output_schema.is_plain_text())\n",
        "print(\"Strict?\", output_schema.is_strict_json_schema())\n",
        "print(\"Schema:\", output_schema.json_schema())\n",
        "print(\"Name:\", output_schema.name())\n",
        "print(\"Validated:\", output_schema.validate_json(json_str=json_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5o7gCGI7Ld5",
        "outputId": "61014ebe-74e7-466c-9f4e-6cd16a4056cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plain Text? False\n",
            "Strict? True\n",
            "Schema: {'properties': {'is_home_work_question': {'title': 'Is Home Work Question', 'type': 'boolean'}, 'response': {'title': 'Response', 'type': 'string'}, 'is_response_correct': {'title': 'Is Response Correct', 'type': 'boolean'}}, 'required': ['is_home_work_question', 'response', 'is_response_correct'], 'title': 'OutputType2', 'type': 'object', 'additionalProperties': False}\n",
            "Name: OutputType2\n",
            "Validated: is_home_work_question=True response='Yes, this is homework.' is_response_correct=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**\n",
        "\n",
        "🟢 **Case 1:** output_type is str or None\n",
        "🔸 This means the agent expects plain text output (not structured JSON).\n",
        "\n",
        "🔸 The model's response is treated as a simple string message.\n",
        "\n",
        "❌ No schema is applied.\n",
        "\n",
        "❌ No JSON validation is needed.\n",
        "\n",
        "✅ The response is used directly as-is.\n",
        "\n"
      ],
      "metadata": {
        "id": "1ZJEvh23_8dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟡 **Case 2**: output_type is a Pydantic model or dict\n",
        "✅ A proper JSON schema is generated from the model or dict.\n",
        "\n",
        "📤 This schema is sent to the LLM (via system prompt/tool call).\n",
        "\n",
        "🤖 The LLM is instructed to respond in valid JSON matching the schema.\n",
        "\n",
        "🧪 After the LLM responds, the raw JSON string is:\n",
        "\n",
        "Validated using the schema (validate_json)\n",
        "\n",
        "Parsed into the output type (e.g. a BaseModel instance)\n",
        "\n",
        "✅ You receive a properly validated object that follows your structure."
      ],
      "metadata": {
        "id": "kG3axHeZApnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "🔴 **Case 3**: output_type is a primitive (like int, list, float, etc.)\n",
        "❌ These cannot be described directly using JSON schema alone in a reliable way.\n",
        "\n",
        "🧊 So they are wrapped in a dict with a special key (e.g. \"output\").\n",
        "\n",
        "📤 The SDK constructs a wrapped schema like:\n",
        "\n",
        "{\n",
        "  \"output\": 123  // or a list, or whatever your primitive type is\n",
        "}\n",
        "\n",
        "🔄 The LLM is asked to respond in this format.\n",
        "\n",
        "✅ The wrapper is unwrapped after validation to return the actual value."
      ],
      "metadata": {
        "id": "faMSzTmsAwDB"
      }
    }
  ]
}
