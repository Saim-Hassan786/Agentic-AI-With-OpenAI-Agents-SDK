# üíª Understanding RunContext, RunContextWrapper & Usage in `openai-agents`

This project demonstrates how **RunContext**, **RunContextWrapper**, and **Usage tracking** work inside the [`openai-agents`](https://pypi.org/project/openai-agents) SDK.
It is designed as a **theory-first walkthrough** with working examples, focusing on **why** these components exist and **how they‚Äôre used** when building context-aware tools for agents.

## üìñ Key Concepts

### 1. RunContext

* `RunContext` is the **context object** you can pass to the `Runner` when executing an Agent.
* It is **not sent to the LLM**.
* Instead, it is only used inside:

  * Custom tools (`@function_tool`)
  * Hooks
  * Callbacks
* This allows you to **enrich tools with external state** (e.g., user profile, location, session info) while keeping prompts clean.


### 2. RunContextWrapper

When you run an agent with context, the SDK wraps your context in a **`RunContextWrapper`**, which gives you two things:

* **`.context`** ‚Üí your original context object (e.g., user name, location).
* **`.usage`** ‚Üí the total usage statistics for that agent run so far.

This wrapper ensures that every tool or callback has access to:

1. The **business context** you provided.
2. The **token usage data** of the ongoing run.


### 3. Usage Tracking

The `usage` object inside `RunContextWrapper` contains detailed stats about how the agent is consuming tokens:

* `requests`: number of LLM calls made.
* `input_tokens`: total tokens sent to the LLM.
* `input_tokens_details`: breakdown (e.g., cached tokens).
* `output_tokens`: tokens generated by the LLM.
* `output_tokens_details`: breakdown (e.g., reasoning tokens).
* `total_tokens`: combined total.
* `.add(other_usage)`: merge usage data across multiple runs.

This lets you **measure cost, performance, and efficiency** across runs.


## üõ†Ô∏è Examples in This Project

### Example 1: Greeting with Context

We define a custom context model:

```python
class Context(BaseModel):
    name: str
    age: int
```

A tool that uses it:

```python
@function_tool
def greet_user_with_context(ctx: RunContextWrapper[Context]):
    return f"Hello {ctx.context.name} you are {ctx.context.age} years old"
```

When running the agent with this context, the tool can directly read the user‚Äôs name and age without needing the LLM to infer it.


### Example 2: Location-based Tool

We define another context model:

```python
class Location(BaseModel):
    city: str
    country: str
```

Tool:

```python
@function_tool
def user_location(ctx: RunContextWrapper[Location]):
    return f"The user is from {ctx.context.city}, {ctx.context.country}"
```

This shows how different agents can be equipped with different **context types** while still benefiting from the same wrapper and usage tracking.


### Example 3: Usage Aggregation

Two runs can have their usage combined:

```python
result_with_context_2.context_wrapper.usage.add(
    result_with_context.context_wrapper.usage
)
```

This is useful for tracking **multi-agent workflows** or **multi-step conversations** where total usage matters.


## üéØ Why This Matters

* **Separation of concerns**: Business context stays outside the LLM prompt.
* **Transparency**: You know exactly how many tokens are used and where.
* **Flexibility**: Tools can directly access structured data without depending on LLM parsing.
* **Scalability**: Usage aggregation helps when building systems with many agents.


## ‚úÖ Summary

* **RunContext**: Passes structured, external context into your run.
* **RunContextWrapper**: Wraps your context with usage tracking.
* **Usage**: Tracks token consumption and can be merged across runs.


