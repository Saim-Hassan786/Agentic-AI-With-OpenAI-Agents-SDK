{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgexabiuCptY3HtcEtRI1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saim-Hassan786/Learn-Agentic-AI-With-OpenAI-Agents-SDK/blob/main/04-Tools/Tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools\n",
        "Tools are additional features of an Agent that let the Agent take actions like retrieving data , calling external APIs, web searching, controlling computer, image generating and many more.There are 3 types of Tools :\n",
        "\n",
        "1. **Hosted Tools**: That are hosted on the LLM Servers like code file search, web search , computer use etc.\n",
        "2. **Python functions** : can also be converted as tools to integrate in our Agent.\n",
        "3. **Agent.as_tools** : Agents can also be converted and used as tools."
      ],
      "metadata": {
        "id": "RV9IizGIITHI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhrHYsAdzNny",
        "outputId": "9813b4d6-e539-4f9e-adfa-64adb85ee676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installing the SDK\n",
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For running event loop\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "J9rYqXSSzYEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre requisites SetUp\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY= userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "from agents import set_default_openai_api,set_default_openai_client,set_tracing_disabled\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")\n",
        "set_default_openai_client(external_client)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "set_tracing_disabled(True)"
      ],
      "metadata": {
        "id": "JaFph2tAzaJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Tools Execution"
      ],
      "metadata": {
        "id": "C9Bn7nVgJzqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Case No.1  === Simple Agent_With_Tool Setup\n",
        "from agents import Agent, Runner, function_tool\n",
        "\n",
        "@function_tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers together\"\"\"\n",
        "    return a + b\n",
        "\n",
        "@function_tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers together\"\"\"\n",
        "    return a * b\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Assistant Agent\",\n",
        "    instructions = \"Help With the user queries\",\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    tools = [add,multiply]\n",
        ")\n",
        "\n",
        "result = await Runner.run(\n",
        "    agent,\n",
        "    input = \"What is the answer of 2+2?\"\n",
        ")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUjNx8HSJvpQ",
        "outputId": "f4f75b6b-9cf5-48d1-94e6-95569e78ff67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The answer to 2+2 is 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Case No.2  === Tools when called no matter what they return that return is always sent to LLM for further processing\n",
        "from agents import Agent, Runner, function_tool\n",
        "\n",
        "@function_tool\n",
        "def add_2(a: int, b: int) :\n",
        "    \"\"\"Add two integers together\"\"\"\n",
        "    return None\n",
        "\n",
        "@function_tool\n",
        "def multiply_2(a: int, b: int):\n",
        "    \"\"\"Multiply two integers together\"\"\"\n",
        "    return \"Do not know the Answer\"\n",
        "\n",
        "\n",
        "agent_2 = Agent(\n",
        "    name=\"Assistant Agent\",\n",
        "    instructions = \"Help With the user queries\",\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    tools = [add_2,multiply_2]\n",
        ")\n",
        "\n",
        "result_2 = await Runner.run(\n",
        "    agent_2,\n",
        "    input = \"What is the answer of 20 multiply by 2 using 'multiply' tool ?\"\n",
        ")\n",
        "print(result_2.final_output)\n",
        "\n",
        "result_3 = await Runner.run(\n",
        "    agent_2,\n",
        "    input = \"What is the answer of adding 100 and 100 using 'add' tool ?\"\n",
        ")\n",
        "\n",
        "print(result_3.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecO6EWSlKwrv",
        "outputId": "6fe20acb-085c-4df2-ac9f-e5a3aa4cc4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, I was unable to find the answer to 20 multiplied by 2 using the 'multiply_2' tool.\n",
            "The tool did not return an answer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other Ways Of Tool Creation"
      ],
      "metadata": {
        "id": "rwLYAw02NeH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from agents import Agent, Runner, FunctionTool,RunContextWrapper\n",
        "\n",
        "class FunctionArgs(BaseModel):\n",
        "  username : str\n",
        "  age : int\n",
        "\n",
        "async def on_invoke_func(ctx:RunContextWrapper,args):\n",
        "  parsed = FunctionArgs.model_validate_json(args)\n",
        "  return f\"Hello {parsed.username} you are {parsed.age} years old ðŸš€\"\n",
        "\n",
        "display_user_info_tool = FunctionTool(\n",
        "    name = \"UserInfo_Disply_Tool\",\n",
        "    description= \"Display Username and Age\",\n",
        "    on_invoke_tool=on_invoke_func,\n",
        "    params_json_schema=FunctionArgs.model_json_schema(),\n",
        "    is_enabled=True,\n",
        "    strict_json_schema=True\n",
        ")\n",
        "\n",
        "agent_with_FunctionTool = Agent(\n",
        "    name=\"Assistant Agent\",\n",
        "    instructions = \"Help With the user queries\",\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    tools = [display_user_info_tool]\n",
        "\n",
        ")\n",
        "\n",
        "result_with_FunctionTool = await Runner.run(\n",
        "    agent_with_FunctionTool,\n",
        "    input = \"My name is Saim Hassan and my age is 25 years , display my info\"\n",
        ")\n",
        "print(result_with_FunctionTool.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_BEsDWFK10y",
        "outputId": "273818ba-259b-4a4f-abd6-8681d71c08fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Saim Hassan you are 25 years old ðŸš€\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from agents import Agent, Runner, FunctionTool,RunContextWrapper\n",
        "\n",
        "class DivisionFuncArgs(BaseModel):\n",
        "  a : int\n",
        "  b : int\n",
        "\n",
        "async def on_invoke_func_div(ctx:RunContextWrapper,args):\n",
        "  parsed = DivisionFuncArgs.model_validate_json(args)\n",
        "  return f\"Hurrah ðŸ˜Š {parsed.a / parsed.b}\"\n",
        "\n",
        "division_tool = FunctionTool(\n",
        "    name = \"Division_Tool\",\n",
        "    description = \"Divide two numbers\",\n",
        "    on_invoke_tool = on_invoke_func_div,\n",
        "    params_json_schema = DivisionFuncArgs.model_json_schema(),\n",
        "    is_enabled = True,\n",
        "    strict_json_schema = True\n",
        ")\n",
        "\n",
        "agent_with_FunctionTool_2 = Agent(\n",
        "    name=\"Assistant Agent\",\n",
        "    instructions = \"Help With the user queries\",\n",
        "    model = \"gemini-2.5-pro\",\n",
        "    tools = [division_tool],\n",
        "    tool_use_behavior=\"stop_on_first_tool\"\n",
        "\n",
        ")\n",
        "\n",
        "result_with_FunctionTool_2 = await Runner.run(\n",
        "    agent_with_FunctionTool_2,\n",
        "    input = \"Divide 100 by 5 using the division_tool and give the answer\"\n",
        ")\n",
        "print(result_with_FunctionTool_2.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7906667c-03d3-4ffc-d035-729a01d47010",
        "id": "BUoMomg-S9p7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hurrah ðŸ˜Š 20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# @function_tool decorator parameters"
      ],
      "metadata": {
        "id": "dPVhMAiVbqj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, function_tool\n",
        "\n",
        "def error_func(ctx:RunContextWrapper,error: Exception) -> str:\n",
        "    print(f\"Error Occured ðŸŽƒ {error}\")\n",
        "    return f\"Error occurred: {str(error)}. Please try again.\"\n",
        "\n",
        "@function_tool(\n",
        "    name_override=\"Addition_tool\",\n",
        "    description_override=\"Add two integers together\",\n",
        "    docstring_style=None,\n",
        "    use_docstring_info=True,\n",
        "    strict_mode=True,\n",
        "    is_enabled=True,\n",
        "    failure_error_function=error_func\n",
        ")\n",
        "def add_with_function_tool_params(a: int, b: int) :\n",
        "    \"\"\"Add two integers together\"\"\"\n",
        "    return a+b\n",
        "\n",
        "\n",
        "@function_tool(\n",
        "    name_override=\"Division_tool\",\n",
        "    description_override=\"Divide two integers\",\n",
        "    docstring_style=None,\n",
        "    use_docstring_info=True,\n",
        "    strict_mode=True,\n",
        "    is_enabled=True,\n",
        "    failure_error_function=error_func\n",
        "    # failure_error_function=None  In case of None, the Error does not goes to LLM , instead it raises above in the Loop and Terminates it.\n",
        ")\n",
        "def division_with_function_tool_params(a: int, b: int):\n",
        "    \"\"\"Divide two integers\"\"\"\n",
        "    return a/b\n",
        "\n",
        "\n",
        "agent_with_function_tool_params = Agent(\n",
        "    name=\"Assistant Agent\",\n",
        "    instructions = \"Help With the user queries\",\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    tools = [add_with_function_tool_params,division_with_function_tool_params],\n",
        "    # tool_use_behavior=\"stop_on_first_tool\"\n",
        ")\n",
        "\n",
        "result_with_function_tool_params = await Runner.run(\n",
        "    agent_with_function_tool_params,\n",
        "    input = \"What is the answer of 115 by 0 using the division tool ?\"\n",
        ")\n",
        "print(result_with_function_tool_params.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juqdOSe5byDG",
        "outputId": "929a7fa4-489b-43f6-8935-37b849fab21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Occured ðŸŽƒ division by zero\n",
            "I cannot divide by zero. Please provide a non-zero number for division.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "Tools can be created by 2 ways :\n",
        "\n",
        "1. **@function_tool**\n",
        "2. **FunctionTool**\n",
        "\n",
        "Both of all return :\n",
        "\n",
        "  - **FuntionToolResult** containing\n",
        "      \n",
        "      - **tool** : FunctionTool\n",
        "      - **output**\n",
        "      - **run_items**\n",
        "\n"
      ],
      "metadata": {
        "id": "ZlMZNpETvD4S"
      }
    }
  ]
}